import torch
from . import soft_dtw
from . import path_soft_dtw 

def pairwise_distances_con(x, y=None):
    '''
    Input: x is a Nxd matrix
           y is an optional Mxd matirx
    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]
            if y is not given then use 'y=x'.
    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2
    '''
    x_norm = (x**2).sum(2).view(x.shape[0], -1, 1)
    if y is not None:
        y_t = torch.transpose(y, 1, 2)
        y_norm = (y**2).sum(2).view(x_norm.shape[0], 1, -1)
    else:
        y_t = torch.transpose(x, 0, 1)
        y_norm = x_norm.view(x_norm.shape[0], 1, -1)
    
    dist = x_norm + y_norm - 2.0 * torch.matmul(x, y_t)
    return torch.clamp(dist, 0.0, float('inf'))

def dilate_loss(outputs, targets, alpha, gamma, device):
	# outputs, targets: shape (batch_size, N_output, 1)
	batch_size, N_output = outputs.shape[0:2]
	loss_shape = 0
	softdtw_batch = soft_dtw.SoftDTWBatch.apply
	# D = torch.zeros((batch_size, N_output,N_output), device=device )
	
	# for k in range(batch_size):
	# 	Dk = soft_dtw.pairwise_distances(targets[k,:,:].view(-1,1),outputs[k,:,:].view(-1,1))
		
	# 	D[k:k+1,:,:] = Dk   
	D = pairwise_distances_con(targets,outputs)  
	loss_shape = softdtw_batch(D,gamma)
	
	path_dtw = path_soft_dtw.PathDTWBatch.apply
	path = path_dtw(D,gamma)           
	Omega =  soft_dtw.pairwise_distances(torch.range(1,N_output).view(N_output,1)).to(device)
	loss_temporal =  torch.sum( path*Omega ) / (N_output*N_output) 
	loss = alpha*loss_shape+ (1-alpha)*loss_temporal
	return loss, loss_shape, loss_temporal